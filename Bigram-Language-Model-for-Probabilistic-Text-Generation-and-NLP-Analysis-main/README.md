# 🧠 Bigram Language Model for Probabilistic Text Generation and NLP Analysis

![Python](https://img.shields.io/badge/Python-3.9+-blue)
![NLP](https://img.shields.io/badge/NLP-Text%20Processing-orange)
![License](https://img.shields.io/badge/License-MIT-green)
![Status](https://img.shields.io/badge/Status-Completed-success)

---

## 📖 Overview

This project implements a **Probabilistic Bigram Language Model** from scratch using **n-gram statistics** and **Maximum Likelihood Estimation (MLE)** for text generation and natural language processing (NLP) analysis.

The model is designed to:
- Learn bigram probabilities from a given text corpus.
- Generate coherent text sequences through probabilistic sampling.
- Evaluate model performance using **perplexity metrics**.
- Handle unseen bigrams effectively using **Laplace smoothing**.

---

## ⚙️ Features

- 🔹 **Tokenization Pipeline:** Efficient preprocessing with character-level encoding.  
- 🔹 **Bigram Probability Matrix:** Built using MLE for statistical text modeling.  
- 🔹 **Laplace Smoothing:** To manage zero-frequency bigrams.  
- 🔹 **Sampling Algorithms:** Generate fluent and meaningful sequences.  
- 🔹 **Perplexity Evaluation:** Quantifies model’s predictive performance.  
- 🔹 **From-Scratch Implementation:** No external NLP frameworks — pure Python and probability theory.

---

## 🧮 Core Concepts

| Concept | Description |
|----------|--------------|
| **Bigram Modeling** | Statistical modeling of word-pair probabilities |
| **Text Generation** | Sampling from the learned bigram distributions |
| **Probability Estimation** | Computing conditional probabilities using frequency counts |
| **Laplace Smoothing** | Ensuring non-zero probabilities for unseen events |
| **Perplexity Analysis** | Evaluating how well the model predicts unseen data |

---

## 🧰 Tech Stack

- **Language:** Python 🐍  
- **Libraries:** NumPy, Pandas, re, math  
- **Techniques:**  
  - N-Gram Statistics  
  - Probabilistic Modeling  
  - Maximum Likelihood Estimation  
  - Statistical Text Generation  

---

